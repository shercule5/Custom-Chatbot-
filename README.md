ECHO is on.
# Custom RAG Chatbot

A custom Retrieval-Augmented Generation (RAG) chatbot built with **FastAPI**, **Vite + React**, and **Ollama** for local LLM inference.  
This project demonstrates how to ingest documents, create embeddings, and interact with a chatbot UI that streams responses in real time.

---

## ðŸš€ Features
- Backend with **FastAPI** + **VectorStore**
- Local LLM inference using **Ollama** (no paid API needed)
- Frontend built with **Vite + React**
- Real-time streaming responses
- Document ingestion (`.txt` supported)
- GitHub-ready structure

---

## ðŸ“‚ Project Structure
